import os
import json
import re
from datetime import date, datetime

import numpy as np
import pandas as pd
import streamlit as st

st.set_page_config(page_title="Investmentæ”¶ç›Šåˆ†æ", layout="wide")
st.title("ğŸ“ˆ Investmentæ”¶ç›Šåˆ†æ")
st.caption("æ­¥éª¤ 1 å¯¼å…¥ Fidelityæ•°æ®ï¼›æ­¥éª¤ 2 æµè§ˆåˆ†æç»“æœï¼›æ­¥éª¤ 3 å¯é€‰æ‹©ä¿å­˜ æ–°Fidelity åˆ° Googleã€‚")

# ====================== Google Sheets è¿æ¥å·¥å…·ï¼ˆæ”¯æŒå¤šç§ secrets å†™æ³•ï¼‰ ======================
import gspread
from google.oauth2.service_account import Credentials
from gspread_dataframe import set_with_dataframe

SCOPE = ["https://www.googleapis.com/auth/spreadsheets"]

def get_spreadsheet_id_from_url(url: str):
    if not url:
        return None
    m = re.search(r"/spreadsheets/d/([a-zA-Z0-9-_]+)", url)
    return m.group(1) if m else None

def load_service_account_info_from_secrets():
    
    if "gcp_service_account" in st.secrets:
        v = st.secrets["gcp_service_account"]
        if isinstance(v, str):
            try:
                return json.loads(v)
            except Exception as e:
                st.error(f"gcp_service_account æ˜¯å­—ç¬¦ä¸²ä½†ä¸æ˜¯æœ‰æ•ˆ JSONï¼š{e}")
                st.stop()
        else:
            try:
                return dict(v)
            except Exception as e:
                st.error(f"æ— æ³•è§£æ gcp_service_accountï¼ˆåº”ä¸ºè¡¨/å­—å…¸æˆ– JSON å­—ç¬¦ä¸²ï¼‰ï¼š{e}")
                st.stop()

    if "gcp_service_account_json" in st.secrets:
        try:
            return json.loads(st.secrets["gcp_service_account_json"])
        except Exception as e:
            st.error(f"gcp_service_account_json ä¸æ˜¯æœ‰æ•ˆ JSONï¼š{e}")
            st.stop()

    st.error("æœªåœ¨ st.secrets ä¸­æ‰¾åˆ° gcp_service_account æˆ– gcp_service_account_jsonã€‚è¯·é…ç½® Service Account JSONã€‚")
    st.stop()

def load_google_sheet_url_from_secrets():
    url = st.secrets.get("google_sheet_url", "").strip() if hasattr(st, "secrets") else ""
    if not url:
        url = os.environ.get("GOOGLE_SHEET_URL", "").strip()
    if not url:
        st.error("æœªåœ¨ st.secrets ä¸­æ‰¾åˆ° google_sheet_urlï¼ˆæˆ–ç¯å¢ƒå˜é‡ GOOGLE_SHEET_URLï¼‰ã€‚è¯·å¡«å…¥ä½ çš„ Google è¡¨æ ¼é“¾æ¥ã€‚")
        st.stop()
    return url

@st.cache_resource(show_spinner=False)
def get_gspread_client_from_secrets():
    info = load_service_account_info_from_secrets()
    creds = Credentials.from_service_account_info(info, scopes=SCOPE)
    gc = gspread.authorize(creds)
    sa_email = info.get("client_email", "(unknown)")
    return gc, sa_email

def get_spreadsheet_from_secrets():
    gc, _ = get_gspread_client_from_secrets()
    gsheet_url = load_google_sheet_url_from_secrets()
    try:
        return gc.open_by_url(gsheet_url)
    except Exception:
        sid = get_spreadsheet_id_from_url(gsheet_url)
        if not sid:
            st.error(f"æ— æ³•ä» google_sheet_url è§£æè¡¨æ ¼IDï¼š{gsheet_url}")
            st.stop()
        try:
            return gc.open_by_key(sid)
        except Exception as ee:
            st.error(f"æ— æ³•æ‰“å¼€ Google è¡¨æ ¼ï¼ˆè¯·ç¡®è®¤å·²å°†è¯¥è¡¨å…±äº«ç»™ Service Account çš„ client_emailï¼‰ï¼š{ee}")
            st.stop()

def ensure_worksheet(sh, title: str, rows=1000, cols=26):
    try:
        return sh.worksheet(title)
    except gspread.exceptions.WorksheetNotFound:
        return sh.add_worksheet(title=title, rows=str(rows), cols=str(cols))

# ===== Helpers: ç”¨ UNFORMATTED_VALUE è¯»å–ï¼Œé¿å…æ•°å­—è¢«è°·æ­Œå½“ä½œæ—¥æœŸ =====
def _col_letter(n):
    s = ""
    while n:
        n, r = divmod(n-1, 26)
        s = chr(65 + r) + s
    return s

def ws_to_dataframe_unformatted(ws, max_rows=5000):
    header = ws.row_values(1)
    if not header:
        return pd.DataFrame()
    ncols = len(header)
    last_col_letter = _col_letter(ncols)
    rng = f"A1:{last_col_letter}{max_rows}"
    vals = ws.get(rng, value_render_option='UNFORMATTED_VALUE')
    rows = [row + [""]*(ncols-len(row)) for row in vals[1:] if any(str(x).strip() != "" for x in row)]
    return pd.DataFrame(rows, columns=header)

def convert_google_serial_to_date(series):
    try:
        return pd.to_datetime(series, unit='D', origin='1899-12-30', errors='coerce').dt.date
    except Exception:
        return pd.to_datetime(series, errors='coerce').dt.date

# ===== å‘¨/æœˆæ±‡æ€» helpers =====
def _to_datetime_safe(s):
    try:
        return pd.to_datetime(s, errors="coerce")
    except Exception:
        return pd.to_datetime(pd.Series(s), errors="coerce")

def aggregate_profit(df, date_col, amount_col, freq="W-MON"):
    """freq: 'W-MON'ï¼ˆå‘¨ä¸€ä¸ºèµ·å§‹ï¼‰æˆ– 'M'ï¼ˆè‡ªç„¶æœˆï¼‰ã€‚"""
    if df is None or df.empty or date_col not in df.columns or amount_col not in df.columns:
        return pd.DataFrame(columns=["æœŸé—´å¼€å§‹", "æ”¶ç›Šåˆè®¡", "ç¬”æ•°"])
    d = df[[date_col, amount_col]].copy()
    d[date_col] = _to_datetime_safe(d[date_col])
    d = d.dropna(subset=[date_col])
    if d.empty:
        return pd.DataFrame(columns=["æœŸé—´å¼€å§‹", "æ”¶ç›Šåˆè®¡", "ç¬”æ•°"])
    if freq.startswith("W"):
        per = d[date_col].dt.to_period(freq)
        start = per.apply(lambda p: p.start_time.normalize())
    else:
        per = d[date_col].dt.to_period("M")
        start = per.apply(lambda p: p.start_time.normalize())
    d["æœŸé—´å¼€å§‹"] = start.dt.date
    g = d.groupby("æœŸé—´å¼€å§‹", as_index=False).agg(æ”¶ç›Šåˆè®¡=(amount_col, "sum"), ç¬”æ•°=(amount_col, "size"))
    return g.sort_values("æœŸé—´å¼€å§‹").reset_index(drop=True)

# è¿æ¥ Google
gc, sa_email = get_gspread_client_from_secrets()
sh = get_spreadsheet_from_secrets()
st.sidebar.header("ğŸ” Google è¿æ¥çŠ¶æ€")
st.sidebar.success("å·²è¿æ¥ Google è¡¨æ ¼")
st.sidebar.caption(f"Service Accountï¼š{sa_email}")
st.sidebar.caption("å¦‚æŠ¥æ— æƒé™ï¼Œè¯·å°†ç›®æ ‡è¡¨æ ¼å…±äº«ç»™ä¸Šé¢è¿™ä¸ªé‚®ç®±ï¼ˆç¼–è¾‘æƒé™ï¼‰ã€‚")

# ====================== Fidelity è®¡ç®—ï¼ˆä¸è®¡è´¹ç”¨ï¼ŒFIFOï¼‰ ======================
def to_float(x):
    if pd.isna(x): return np.nan
    s = str(x).strip().replace(",", "").replace("$","")
    if s.startswith("(") and s.endswith(")"):
        s = "-" + s[1:-1]
    try:
        return float(s)
    except:
        return np.nan

def detect_columns(df):
    cols = {c.strip().lower(): c for c in df.columns}
    date_col = cols.get("trade date") or cols.get("run date") or cols.get("settlement date") or cols.get("date") or list(df.columns)[0]
    ticker_col = cols.get("symbol") or cols.get("ticker") or cols.get("security") or cols.get("instrument")
    action_col = cols.get("action") or cols.get("description") or cols.get("type")
    qty_col = cols.get("quantity") or cols.get("qty") or cols.get("shares")
    price_col = cols.get("price ($)") or cols.get("price") or cols.get("fill price")
    account_col = (
        cols.get("account name") or cols.get("account") or cols.get("account type") or cols.get("account description")
        or cols.get("account number") or cols.get("acct")
    )
    need = [date_col, ticker_col, action_col, qty_col, price_col]
    if any(x is None for x in need):
        st.error("æ— æ³•è¯†åˆ«å¿…è¦åˆ—ï¼šæ—¥æœŸã€ä»£ç ã€æ“ä½œã€æ•°é‡ã€ä»·æ ¼ã€‚"); return None
    return {"date":date_col,"ticker":ticker_col,"action":action_col,"qty":qty_col,"price":price_col,"account":account_col}

def map_action(s: str):
    s = str(s).upper()
    if "SOLD" in s: return "SELL"
    if "BOUGHT" in s: return "BUY"
    return None

def fmt_pct(x, digits=4):
    if x is None or pd.isna(x) or not np.isfinite(x): return "â€”"
    return f"{x*100:.{digits}f}%"

def prepare_trades(df: pd.DataFrame):
    mp = detect_columns(df)
    if mp is None: return None
    d = df.copy()
    d["æ—¥æœŸ"] = pd.to_datetime(d[mp["date"]], errors="coerce")
    d["ä»£ç "] = d[mp["ticker"]].astype(str).str.strip().str.upper()
    d["æ–¹å‘"] = d[mp["action"]].map(map_action)
    d["æ•°é‡"] = d[mp["qty"]].apply(to_float).abs()
    d["ä»·æ ¼"] = d[mp["price"]].apply(to_float)
    if mp.get("account") is not None:
        d["è´¦æˆ·"] = d[mp["account"]].astype(str).str.strip()
        d.loc[d["è´¦æˆ·"].eq("") | d["è´¦æˆ·"].isna(), "è´¦æˆ·"] = "é»˜è®¤è´¦æˆ·"
    else:
        d["è´¦æˆ·"] = "é»˜è®¤è´¦æˆ·"
    d = d[(~d["æ—¥æœŸ"].isna()) & (~d["ä»£ç "].isna()) & (~d["æ–¹å‘"].isna()) & (d["æ•°é‡"]>0) & (~d["ä»·æ ¼"].isna())]
    d = d.sort_values(["è´¦æˆ·","ä»£ç ","æ—¥æœŸ"]).reset_index(drop=True)
    return d

def fifo_analyze(trade_df: pd.DataFrame):
    realized = []
    holdings = {}
    for _, row in trade_df.iterrows():
        acct=row.get("è´¦æˆ·","é»˜è®¤è´¦æˆ·")
        tkr=row["ä»£ç "]; side=row["æ–¹å‘"]; qty=float(row["æ•°é‡"]); price=float(row["ä»·æ ¼"]); date=row["æ—¥æœŸ"]
        key=(acct,tkr)
        holdings.setdefault(key, [])
        if side=="BUY":
            total_cost = qty*price
            holdings[key].append({"date":date, "qty":qty, "cps": total_cost/qty})
        elif side=="SELL":
            rem = qty
            while rem>0 and holdings.get(key,[]):
                lot = holdings[key][0]
                used = min(rem, lot["qty"])
                pnl_wo = used*(price - lot["cps"])
                cost_used = used*lot["cps"]
                days = max((date - lot["date"]).days, 0)
                roi = pnl_wo / cost_used if cost_used>0 else np.nan
                ann = ((1+roi)**(365.0/days)-1) if (days>0 and pd.notna(roi)) else roi
                realized.append({
                    "è´¦æˆ·": acct,
                    "ä»£ç ": tkr,
                    "ä¹°å…¥æ—¥æœŸ": lot["date"].date(),
                    "ä¹°å…¥æˆæœ¬(æ¯è‚¡)": lot["cps"],
                    "å–å‡ºæ—¥æœŸ": date.date(),
                    "å–å‡ºä»·": price,
                    "å–å‡ºè‚¡æ•°": used,
                    "æŒæœ‰å¤©æ•°": days,
                    "åˆ©æ¶¦(ä¸å«è´¹ç”¨)": pnl_wo,
                    "æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)": roi,
                    "å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)": ann
                })
                lot["qty"] -= used
                rem -= used
                if lot["qty"] <= 1e-9:
                    holdings[key].pop(0)

    hold_rows=[]
    for (acct,tkr),lots in holdings.items():
        qty = sum(l["qty"] for l in lots)
        if qty<=0: continue
        cost = sum(l["qty"]*l["cps"] for l in lots)
        hold_rows.append({"è´¦æˆ·":acct, "ä»£ç ":tkr, "æŒä»“æ•°é‡":qty, "æŒä»“å‡ä»·":cost/qty, "æŒä»“æ‰¹æ¬¡":len(lots)})
    holdings_df = pd.DataFrame(hold_rows).sort_values(["è´¦æˆ·","ä»£ç "])

    realized_df = pd.DataFrame(realized)

    if not realized_df.empty:
        realized_df["æŠ•å…¥æœ¬é‡‘"] = realized_df["å–å‡ºè‚¡æ•°"] * realized_df["ä¹°å…¥æˆæœ¬(æ¯è‚¡)"]
        invested_total = realized_df["æŠ•å…¥æœ¬é‡‘"].sum()
        total_profit_excl = realized_df["åˆ©æ¶¦(ä¸å«è´¹ç”¨)"].sum()
        total_roi_excl = (total_profit_excl / invested_total) if invested_total>0 else np.nan
        first_buy_date = trade_df.loc[trade_df["æ–¹å‘"]=="BUY","æ—¥æœŸ"].min()
        today = pd.Timestamp.today().normalize()
        span_days = max((today - first_buy_date).days, 1) if pd.notna(first_buy_date) else np.nan
        total_ann_excl = (1 + total_roi_excl)**(365.0/span_days) - 1 if (pd.notna(total_roi_excl) and pd.notna(span_days)) else np.nan

        per_ticker = realized_df.groupby("ä»£ç ").apply(
            lambda g: pd.Series({
                "å·²å–å‡ºç¬”æ•°": len(g),
                "å·²å–å‡ºè‚¡æ•°": g["å–å‡ºè‚¡æ•°"].sum(),
                "åˆ©æ¶¦åˆè®¡(ä¸å«è´¹ç”¨)": g["åˆ©æ¶¦(ä¸å«è´¹ç”¨)"].sum(),
                "æŠ•å…¥æœ¬é‡‘åˆè®¡": g["æŠ•å…¥æœ¬é‡‘"].sum(),
                "æˆæœ¬åŠ æƒæ”¶ç›Šç‡(ä¸å«è´¹ç”¨)": (g["åˆ©æ¶¦(ä¸å«è´¹ç”¨)"].sum()/g["æŠ•å…¥æœ¬é‡‘"].sum()) if g["æŠ•å…¥æœ¬é‡‘"].sum()>0 else np.nan,
                "æˆæœ¬åŠ æƒå¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)": ((g["å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"]*g["æŠ•å…¥æœ¬é‡‘"]).sum()/g["æŠ•å…¥æœ¬é‡‘"].sum()) if g["æŠ•å…¥æœ¬é‡‘"].sum()>0 else np.nan
            })
        ).reset_index()
    else:
        invested_total=0.0; total_profit_excl=0.0
        total_roi_excl=np.nan; total_ann_excl=np.nan; span_days=np.nan
        per_ticker = pd.DataFrame(columns=["ä»£ç ","å·²å–å‡ºç¬”æ•°","å·²å–å‡ºè‚¡æ•°","åˆ©æ¶¦åˆè®¡(ä¸å«è´¹ç”¨)","æŠ•å…¥æœ¬é‡‘åˆè®¡","æˆæœ¬åŠ æƒæ”¶ç›Šç‡(ä¸å«è´¹ç”¨)","æˆæœ¬åŠ æƒå¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"])

    totals = {
        "æ€»æŠ•å…¥æœ¬é‡‘": invested_total,
        "æ€»åˆ©æ¶¦(ä¸å«è´¹ç”¨)": total_profit_excl,
        "æ€»ä½“æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)": total_roi_excl,
        "æ€»ä½“å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)": total_ann_excl,
        "ç»Ÿè®¡åŒºé—´å¤©æ•°": span_days
    }
    return holdings_df, realized_df, per_ticker, totals

def apply_pct_format(df, cols, digits=4):
    df = df.copy()
    for c in cols:
        if c in df.columns:
            df[c] = df[c].apply(lambda v: fmt_pct(v, digits))
    return df

# ====================== ğŸŸ¢ æ­¥éª¤ 1ï½œå¯¼å…¥ Fidelity æ•°æ® ======================
st.subheader("ğŸŸ¢ æ­¥éª¤ 1ï½œå¯¼å…¥ Fidelity æ•°æ®")
st.caption("é€‰æ‹©æ•°æ®æ¥æºï¼šä» Google è¯»å–å†å²ç»“æœï¼ˆé»˜è®¤ï¼‰æˆ–ä¸Šä¼ æ–°çš„ Fidelity CSVã€‚")

holdings_df = pd.DataFrame(); realized_df = pd.DataFrame(); per_ticker = pd.DataFrame(); totals = None

src_choice = st.radio("é€‰æ‹©æ•°æ®æ¥æºï¼š", options=["ä» Google è¡¨æ ¼è¯»å–", "ä¸Šä¼ æ–°çš„ Fidelity CSV"], index=0, horizontal=True)

if src_choice == "ä¸Šä¼ æ–°çš„ Fidelity CSV":
    raw_csv = st.file_uploader("é€‰æ‹© CSV æ–‡ä»¶ï¼ˆFidelity å¯¼å‡ºï¼‰", type=["csv"], key="u_fid_csv")
    if raw_csv is not None:
        try:
            raw_df = pd.read_csv(raw_csv)
            trade_df = prepare_trades(raw_df)
            if trade_df is None or trade_df.empty:
                st.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆçš„ä¹°å…¥/å–å‡ºè®°å½•ã€‚")
            else:
                holdings_df, realized_df, per_ticker, totals = fifo_analyze(trade_df)
                st.success("Fidelity CSV å·²è§£æã€‚")
        except Exception as e:
            st.error(f"åŸå§‹CSVè§£æå¤±è´¥ï¼š{e}")
else:
    try:
        ws_h = ensure_worksheet(sh, "Fidelity_Holdings")
        ws_r = ensure_worksheet(sh, "Fidelity_Realized")
        ws_p = ensure_worksheet(sh, "Fidelity_PerTicker")
        ws_t = ensure_worksheet(sh, "Fidelity_Totals")
        holdings_df = ws_to_dataframe_unformatted(ws_h).dropna(how="all")
        realized_df = ws_to_dataframe_unformatted(ws_r).dropna(how="all")
        per_ticker = ws_to_dataframe_unformatted(ws_p).dropna(how="all")
        totals_df = ws_to_dataframe_unformatted(ws_t).dropna(how="all")
        if not totals_df.empty and "key" in totals_df.columns and "value" in totals_df.columns:
            totals = {row["key"]: row["value"] for _, row in totals_df.iterrows()}
        if not realized_df.empty:
            for col in ["ä¹°å…¥æ—¥æœŸ","å–å‡ºæ—¥æœŸ"]:
                if col in realized_df.columns:
                    realized_df[col] = convert_google_serial_to_date(realized_df[col])
        if not holdings_df.empty and "ä¹°å…¥æ—¥æœŸ" in holdings_df.columns:
            holdings_df["ä¹°å…¥æ—¥æœŸ"] = convert_google_serial_to_date(holdings_df["ä¹°å…¥æ—¥æœŸ"])
        st.success("å·²ä» Google åŠ è½½ Fidelity ç»“æœã€‚")
    except Exception as e:
        st.error(f"è¯»å–å¤±è´¥ï¼š{e}")

# ====================== ğŸ”µ æ­¥éª¤ 2ï½œæµè§ˆç»“æœ ======================
st.subheader("ğŸ”µ æ­¥éª¤ 2ï½œæµè§ˆç»“æœ")
st.caption("åœ¨ä¸‹æ–¹å„ä¸ª Tab æŸ¥çœ‹ Fidelity ç»“æœï¼›ç¬¬ 4 ä¸ª Tab è‡ªåŠ¨ä» Google è¯»å–æ‰‹åŠ¨æ¡ç›®ã€‚")

tab1, tab2, tab3, tab4, tab5 = st.tabs(["â‘  å½“å‰ä»æŒæœ‰ï¼ˆFidelityï¼‰", "â‘¡ å·²å–å‡ºæ€»åˆ©æ¶¦ï¼ˆFidelityï¼‰", "â‘¢ æ¯åªæ”¶ç›Šç‡ä¸å¹´åŒ–ï¼ˆFidelityï¼‰", "â‘£ æ‰‹åŠ¨æ¡ç›®", "â‘¤ å‘¨/æœˆæ”¶ç›Šæ±‡æ€»"])

with tab1:
    st.subheader("ğŸ“Œ å½“å‰ä»æŒæœ‰ï¼ˆåŠ æƒå‡ä»· & æ•°é‡ï¼‰")
    if not holdings_df.empty:
        if "è´¦æˆ·" in holdings_df.columns:
            for acct, dfsub in holdings_df.groupby("è´¦æˆ·"):
                st.markdown(f"**è´¦æˆ·ï¼š{acct}**")
                st.dataframe(dfsub.round(6).reset_index(drop=True), use_container_width=True)
                st.markdown(" ")
        else:
            st.markdown("**è´¦æˆ·ï¼šé»˜è®¤è´¦æˆ·**")
            st.dataframe(holdings_df.round(6), use_container_width=True)
    else:
        st.write("ï¼ˆæš‚æ— æ•°æ®ï¼‰")

with tab2:
    st.subheader("ğŸ’° å·²å–å‡ºéƒ¨åˆ†æ€»åˆ©æ¶¦ï¼ˆä»¥åŠæ€»ä½“æ”¶ç›Šç‡ & å¹´åŒ–ï¼‰")
    if totals is None or (isinstance(totals, dict) and len(totals)==0):
        st.write("ï¼ˆæš‚æ— æ•°æ®ï¼‰")
    else:
        try:
            c1, c2 = st.columns(2)
            c1.metric("æ€»åˆ©æ¶¦ï¼ˆä¸å«è´¹ç”¨ï¼‰", f"{float(totals['æ€»åˆ©æ¶¦(ä¸å«è´¹ç”¨)']):,.2f}")
            c2.metric("æ€»æŠ•å…¥æœ¬é‡‘", f"{float(totals['æ€»æŠ•å…¥æœ¬é‡‘']):,.2f}")
            def pct_fmt(v): 
                try: 
                    return f"{float(v)*100:.4f}%"
                except: 
                    return "â€”"
            c3, c4 = st.columns(2)
            c3.metric("æ€»ä½“æ”¶ç›Šç‡ï¼ˆä¸å«è´¹ç”¨ï¼‰", pct_fmt(totals['æ€»ä½“æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)']))
            c4.metric("æ€»ä½“å¹´åŒ–æ”¶ç›Šç‡ï¼ˆä¸å«è´¹ç”¨ï¼‰", pct_fmt(totals['æ€»ä½“å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)']))
            span_days = int(float(totals["ç»Ÿè®¡åŒºé—´å¤©æ•°"])) if "ç»Ÿè®¡åŒºé—´å¤©æ•°" in totals and totals["ç»Ÿè®¡åŒºé—´å¤©æ•°"] not in [None, ""] else "â€”"
            st.caption(f"ç»Ÿè®¡åŒºé—´ï¼šè‡ªé¦–æ¬¡ä¹°å…¥è‡³ä»Šæ—¥ï¼Œåˆè®¡ {span_days} å¤©")
        except Exception:
            st.write("ï¼ˆTotals å­—æ®µæ ¼å¼ä¸å®Œæ•´ï¼‰")
        with st.expander("ğŸ“„ å–å‡ºæ‹†åˆ†è‡³ä¹°å…¥æ‰¹æ¬¡ï¼ˆFIFO æ˜ç»†ï¼‰"):
            if 'æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)' in realized_df.columns and realized_df['æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)'].dtype != 'O':
                realized_df_fmt = realized_df.copy()
                realized_df_fmt["æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"] = realized_df_fmt["æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"].apply(lambda v: fmt_pct(v, 4))
                realized_df_fmt["å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"] = realized_df_fmt["å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"].apply(lambda v: fmt_pct(v, 4))
                st.dataframe(realized_df_fmt, use_container_width=True)
            else:
                st.dataframe(realized_df, use_container_width=True)

with tab3:
    st.subheader("ğŸ“Š æ¯åªå·²å–å‡ºè‚¡ç¥¨çš„æ”¶ç›Šç‡ä¸å¹´åŒ–ï¼ˆä»…é’ˆå¯¹å·²å–å‡ºéƒ¨åˆ†ï¼‰")
    if per_ticker is not None and not per_ticker.empty:
        pt = per_ticker.copy()
        for col in ["æˆæœ¬åŠ æƒæ”¶ç›Šç‡(ä¸å«è´¹ç”¨)","æˆæœ¬åŠ æƒå¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)"]:
            if col in pt.columns and pt[col].dtype != 'O':
                pt[col] = pt[col].apply(lambda v: fmt_pct(v, 6))
        st.dataframe(pt.round(6), use_container_width=True)
        st.markdown("â€”â€”")
        if totals and isinstance(totals, dict):
            try:
                st.write(f"**æ€»æŠ•å…¥æœ¬é‡‘**ï¼š{float(totals['æ€»æŠ•å…¥æœ¬é‡‘']):,.2f}")
                st.write(f"**æ€»ä½“æ”¶ç›Šç‡ï¼ˆä¸å«è´¹ç”¨ï¼‰**ï¼š{float(totals['æ€»ä½“æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)'])*100:.6f}%")
                st.write(f"**æ€»ä½“å¹´åŒ–æ”¶ç›Šç‡ï¼ˆä¸å«è´¹ç”¨ï¼‰**ï¼š{float(totals['æ€»ä½“å¹´åŒ–æ”¶ç›Šç‡(ä¸å«è´¹ç”¨)'])*100:.6f}%")
            except Exception:
                pass
    else:
        st.write("ï¼ˆæš‚æ— æ•°æ®ï¼‰")

with tab4:
    st.subheader("âœï¸ æ‰‹åŠ¨æ¡ç›®ï¼ˆåªè¯»ï¼Œè‡ªåŠ¨ä» Google è¯»å–ï¼‰")
    st.caption("åˆ—ï¼šä»£ç ï½œæ—¥æœŸï½œæˆæœ¬ï½œæ”¶ç›Šé‡‘é¢ï½œå¤‡æ³¨ã€‚é¡µé¢è‡ªåŠ¨è®¡ç®—æ¯è¡Œæ”¶ç›Šç‡å¹¶æ˜¾ç¤ºåˆè®¡ã€‚")
    try:
        ws_manual = ensure_worksheet(sh, "ManualEntries")
        dfm = ws_to_dataframe_unformatted(ws_manual).dropna(how="all")
        expected = ["ä»£ç ","æ—¥æœŸ","æˆæœ¬","æ”¶ç›Šé‡‘é¢","å¤‡æ³¨"]
        if not dfm.empty:
            for col in expected:
                if col not in dfm.columns:
                    dfm[col] = "" if col in ["ä»£ç ","æ—¥æœŸ","å¤‡æ³¨"] else 0.0
            dfm = dfm[expected]
        else:
            dfm = pd.DataFrame(columns=expected)
        if "æ—¥æœŸ" in dfm.columns:
            dfm["æ—¥æœŸ"] = convert_google_serial_to_date(dfm["æ—¥æœŸ"])
        def calc_roi(row):
            c = row.get("æˆæœ¬", 0.0)
            a = row.get("æ”¶ç›Šé‡‘é¢", 0.0)
            if pd.isna(c) or c == 0:
                return np.nan
            try:
                return float(a)/float(c)
            except:
                return np.nan
        if not dfm.empty:
            dfm["æ”¶ç›Šç‡"] = dfm.apply(calc_roi, axis=1)
            dfm_disp = dfm.copy()
            dfm_disp["æ”¶ç›Šç‡"] = dfm_disp["æ”¶ç›Šç‡"].apply(lambda v: fmt_pct(v, 4))
            st.dataframe(dfm_disp, use_container_width=True)
            st.metric("æ‰‹åŠ¨æ¡ç›®æ”¶ç›Šåˆè®¡", f"{dfm['æ”¶ç›Šé‡‘é¢'].sum():,.2f}")
        else:
            st.write("ï¼ˆGoogle ä¸Šæš‚æ— æ‰‹åŠ¨æ¡ç›®ï¼‰")
            st.metric("æ‰‹åŠ¨æ¡ç›®æ”¶ç›Šåˆè®¡", f"{0.0:,.2f}")
    except Exception as e:
        st.error(f"è¯»å–æ‰‹åŠ¨æ¡ç›®å¤±è´¥ï¼š{e}")

with tab5:
    st.subheader("ğŸ“… å‘¨/æœˆæ”¶ç›Šæ±‡æ€»ï¼ˆå·²å®ç°æ”¶ç›Šï¼‰")
    st.caption("å£å¾„ï¼šFidelity æŒ‰å–å‡ºæ—¥æœŸèšåˆâ€œåˆ©æ¶¦(ä¸å«è´¹ç”¨)â€ï¼›æ‰‹åŠ¨æ¡ç›®æŒ‰â€œæ—¥æœŸâ€èšåˆâ€œæ”¶ç›Šé‡‘é¢â€ã€‚æ˜¾ç¤ºåˆå¹¶æ€»è§ˆ + åˆ†æ¥æºã€‚")
    fid_week = aggregate_profit(realized_df, "å–å‡ºæ—¥æœŸ", "åˆ©æ¶¦(ä¸å«è´¹ç”¨)", freq="W-MON") if realized_df is not None else pd.DataFrame()
    fid_month = aggregate_profit(realized_df, "å–å‡ºæ—¥æœŸ", "åˆ©æ¶¦(ä¸å«è´¹ç”¨)", freq="M") if realized_df is not None else pd.DataFrame()
    try:
        ws_manual = ensure_worksheet(sh, "ManualEntries")
        dfm = ws_to_dataframe_unformatted(ws_manual).dropna(how="all")
        if not dfm.empty:
            expected = ["ä»£ç ","æ—¥æœŸ","æˆæœ¬","æ”¶ç›Šé‡‘é¢","å¤‡æ³¨"]
            for col in expected:
                if col not in dfm.columns:
                    dfm[col] = "" if col in ["ä»£ç ","æ—¥æœŸ","å¤‡æ³¨"] else 0.0
            dfm = dfm[expected]
            dfm["æ—¥æœŸ"] = convert_google_serial_to_date(dfm["æ—¥æœŸ"])
            man_week = aggregate_profit(dfm, "æ—¥æœŸ", "æ”¶ç›Šé‡‘é¢", freq="W-MON")
            man_month = aggregate_profit(dfm, "æ—¥æœŸ", "æ”¶ç›Šé‡‘é¢", freq="M")
        else:
            man_week = pd.DataFrame(columns=["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡","ç¬”æ•°"])
            man_month = pd.DataFrame(columns=["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡","ç¬”æ•°"])
    except Exception:
        man_week = pd.DataFrame(columns=["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡","ç¬”æ•°"])
        man_month = pd.DataFrame(columns=["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡","ç¬”æ•°"])

    def combine(a, b):
        aa = a[["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡"]].copy() if (a is not None and not a.empty) else pd.DataFrame(columns=["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡"]).assign(æ”¶ç›Šåˆè®¡=0.0)
        bb = b[["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡"]].copy() if (b is not None and not b.empty) else pd.DataFrame(columns=["æœŸé—´å¼€å§‹","æ”¶ç›Šåˆè®¡"]).assign(æ”¶ç›Šåˆè®¡=0.0)
        g = pd.merge(aa, bb, on="æœŸé—´å¼€å§‹", how="outer", suffixes=("_Fidelity","_æ‰‹åŠ¨")).fillna(0.0)
        g["æ”¶ç›Šåˆè®¡"] = g["æ”¶ç›Šåˆè®¡_Fidelity"] + g["æ”¶ç›Šåˆè®¡_æ‰‹åŠ¨"]
        return g.sort_values("æœŸé—´å¼€å§‹").reset_index(drop=True)

    total_week = combine(fid_week, man_week)
    total_month = combine(fid_month, man_month)

    subtab1, subtab2, subtab3 = st.tabs(["åˆå¹¶æ€»è§ˆ", "Fidelity", "æ‰‹åŠ¨æ¡ç›®"])
    with subtab1:
        st.markdown("**å‘¨åº¦**")
        st.dataframe(total_week, use_container_width=True)
        st.markdown("**æœˆåº¦**")
        st.dataframe(total_month, use_container_width=True)
    with subtab2:
        c1, c2 = st.columns(2)
        c1.markdown("**Fidelity å‘¨åº¦**"); c1.dataframe(fid_week, use_container_width=True)
        c2.markdown("**Fidelity æœˆåº¦**"); c2.dataframe(fid_month, use_container_width=True)
    with subtab3:
        c1, c2 = st.columns(2)
        c1.markdown("**æ‰‹åŠ¨ å‘¨åº¦**"); c1.dataframe(man_week, use_container_width=True)
        c2.markdown("**æ‰‹åŠ¨ æœˆåº¦**"); c2.dataframe(man_month, use_container_width=True)

st.markdown("---")

# ====================== ğŸŸ£ æ­¥éª¤ 3ï½œä¿å­˜åˆ° Googleï¼ˆä»…è¦†ç›– Fidelityï¼‰ ======================
st.subheader("ğŸŸ£ æ­¥éª¤ 3ï½œä¿å­˜åˆ° Googleï¼ˆä»…è¦†ç›– Fidelity æ•°æ®ï¼‰")
st.caption("ç‚¹å‡»ååªå†™å…¥ Fidelity_Holdings / Fidelity_Realized / Fidelity_PerTicker / Fidelity_Totals å››å¼ è¡¨ï¼›ManualEntries ä¸æ”¹åŠ¨ã€‚")
if st.button("ğŸ’¾ ä¿å­˜æœ€æ–° Fidelity æ•°æ®åˆ° Googleï¼ˆè¦†ç›–æ—§æ•°æ®ï¼‰"):
    try:
        ws_h = ensure_worksheet(sh, "Fidelity_Holdings")
        ws_r = ensure_worksheet(sh, "Fidelity_Realized")
        ws_p = ensure_worksheet(sh, "Fidelity_PerTicker")
        ws_t = ensure_worksheet(sh, "Fidelity_Totals")
        def safe_df(df): 
            return df.reset_index(drop=True) if df is not None else pd.DataFrame()
        set_with_dataframe(ws_h, safe_df(holdings_df))
        set_with_dataframe(ws_r, safe_df(realized_df))
        set_with_dataframe(ws_p, safe_df(per_ticker))
        totals_map = {} if (not isinstance(totals, dict)) else totals
        tdf = pd.DataFrame({"key": list(totals_map.keys()), "value": list(totals_map.values())})
        set_with_dataframe(ws_t, tdf)
        st.success("å·²è¦†ç›–å†™å…¥ Fidelity å››å¼ è¡¨ï¼›ManualEntries æœªæ”¹åŠ¨ã€‚")
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")
